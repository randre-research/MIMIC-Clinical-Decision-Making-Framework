{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logging import read_from_pickle_file\n",
    "\n",
    "from os.path import join\n",
    "from dataset.utils import load_hadm_from_file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# from evaluators.appendicitis_evaluator import AppendicitisEvaluator\n",
    "# from evaluators.cholecystitis_evaluator import CholecystitisEvaluator\n",
    "# from evaluators.diverticulitis_evaluator import DiverticulitisEvaluator\n",
    "# from evaluators.pancreatitis_evaluator import PancreatitisEvaluator\n",
    "# from run import load_evaluator\n",
    "# from utils.nlp import latex_escape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20890008</th>\n",
       "      <th>27892518</th>\n",
       "      <th>21807759</th>\n",
       "      <th>20345216</th>\n",
       "      <th>24078130</th>\n",
       "      <th>23919775</th>\n",
       "      <th>27022201</th>\n",
       "      <th>24238743</th>\n",
       "      <th>26687335</th>\n",
       "      <th>21409557</th>\n",
       "      <th>...</th>\n",
       "      <th>28843301</th>\n",
       "      <th>23068441</th>\n",
       "      <th>25220207</th>\n",
       "      <th>23395859</th>\n",
       "      <th>28148829</th>\n",
       "      <th>27971821</th>\n",
       "      <th>22531080</th>\n",
       "      <th>26413006</th>\n",
       "      <th>28996362</th>\n",
       "      <th>26593491</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Diagnosis</th>\n",
       "      <td>Acute Appendicitis</td>\n",
       "      <td>Acute Appendicitis</td>\n",
       "      <td>Acute Appendicitis</td>\n",
       "      <td>Acute Appendicitis</td>\n",
       "      <td>Acute Appendicitis</td>\n",
       "      <td>Acute Appendicitis</td>\n",
       "      <td>Acute Appendicitis with Perforation</td>\n",
       "      <td>Acute Appendicitis</td>\n",
       "      <td>Acute Appendicitis</td>\n",
       "      <td>Acute Appendicitis</td>\n",
       "      <td>...</td>\n",
       "      <td>Acute Appendicitis</td>\n",
       "      <td>Acute Appendicitis</td>\n",
       "      <td>Perforated Appendicitis</td>\n",
       "      <td>Acute Appendicitis</td>\n",
       "      <td>Acute Appendicitis with Rupture and Abscess Fo...</td>\n",
       "      <td>Acute Appendicitis</td>\n",
       "      <td>Acute Appendicitis</td>\n",
       "      <td>Acute Appendicitis</td>\n",
       "      <td>Acute Appendicitis</td>\n",
       "      <td>Acute Appendicitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Probabilities</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrieval</th>\n",
       "      <td>[{'chunk_id': 'chunk_423', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_263', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_423', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_242', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_82', 'document_reference'...</td>\n",
       "      <td>[{'chunk_id': 'chunk_263', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_263', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_263', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_592', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_263', 'document_reference...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'chunk_id': 'chunk_263', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_263', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_423', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_423', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_263', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_243', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_263', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_243', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_263', 'document_reference...</td>\n",
       "      <td>[{'chunk_id': 'chunk_263', 'document_reference...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 957 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        20890008  \\\n",
       "Diagnosis                                     Acute Appendicitis   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_423', 'document_reference...   \n",
       "\n",
       "                                                        27892518  \\\n",
       "Diagnosis                                     Acute Appendicitis   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_263', 'document_reference...   \n",
       "\n",
       "                                                        21807759  \\\n",
       "Diagnosis                                     Acute Appendicitis   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_423', 'document_reference...   \n",
       "\n",
       "                                                        20345216  \\\n",
       "Diagnosis                                     Acute Appendicitis   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_242', 'document_reference...   \n",
       "\n",
       "                                                        24078130  \\\n",
       "Diagnosis                                     Acute Appendicitis   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_82', 'document_reference'...   \n",
       "\n",
       "                                                        23919775  \\\n",
       "Diagnosis                                     Acute Appendicitis   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_263', 'document_reference...   \n",
       "\n",
       "                                                        27022201  \\\n",
       "Diagnosis                    Acute Appendicitis with Perforation   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_263', 'document_reference...   \n",
       "\n",
       "                                                        24238743  \\\n",
       "Diagnosis                                     Acute Appendicitis   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_263', 'document_reference...   \n",
       "\n",
       "                                                        26687335  \\\n",
       "Diagnosis                                     Acute Appendicitis   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_592', 'document_reference...   \n",
       "\n",
       "                                                        21409557  ...  \\\n",
       "Diagnosis                                     Acute Appendicitis  ...   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...  ...   \n",
       "Retrieval      [{'chunk_id': 'chunk_263', 'document_reference...  ...   \n",
       "\n",
       "                                                        28843301  \\\n",
       "Diagnosis                                     Acute Appendicitis   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_263', 'document_reference...   \n",
       "\n",
       "                                                        23068441  \\\n",
       "Diagnosis                                     Acute Appendicitis   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_263', 'document_reference...   \n",
       "\n",
       "                                                        25220207  \\\n",
       "Diagnosis                                Perforated Appendicitis   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_423', 'document_reference...   \n",
       "\n",
       "                                                        23395859  \\\n",
       "Diagnosis                                     Acute Appendicitis   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_423', 'document_reference...   \n",
       "\n",
       "                                                        28148829  \\\n",
       "Diagnosis      Acute Appendicitis with Rupture and Abscess Fo...   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_263', 'document_reference...   \n",
       "\n",
       "                                                        27971821  \\\n",
       "Diagnosis                                     Acute Appendicitis   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_243', 'document_reference...   \n",
       "\n",
       "                                                        22531080  \\\n",
       "Diagnosis                                     Acute Appendicitis   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_263', 'document_reference...   \n",
       "\n",
       "                                                        26413006  \\\n",
       "Diagnosis                                     Acute Appendicitis   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_243', 'document_reference...   \n",
       "\n",
       "                                                        28996362  \\\n",
       "Diagnosis                                     Acute Appendicitis   \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "Retrieval      [{'chunk_id': 'chunk_263', 'document_reference...   \n",
       "\n",
       "                                                        26593491  \n",
       "Diagnosis                                     Acute Appendicitis  \n",
       "Probabilities  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...  \n",
       "Retrieval      [{'chunk_id': 'chunk_263', 'document_reference...  \n",
       "\n",
       "[3 rows x 957 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"D:\\Users\\orosh\\DOCUME~1\\Research\\Datasets\\MIMIC-~1.1-F\\logs\\APPEND~2.0BP\\APPEND~1.PKL\"\n",
    "\n",
    "PATH = r\"D:\\Users\\orosh\\DOCUME~1\\Research\\Datasets\\MIMIC-~1.1-F\\logs\\APPEND~2.0BP\\APPEND~1.PKL\"\n",
    "\n",
    "#load the table using read_from_pickle_file and print the columns and the first 5 rows\n",
    "table = read_from_pickle_file(PATH)\n",
    "\n",
    "#table is a generator, turn it into a handy pandas dataframe by following this code example:\n",
    "# results = []\n",
    "# for r in read_from_pickle_file(glob.glob(results_log_path)[0]):\n",
    "#     results.append(r)\n",
    "# results = {k: v for d in results for k, v in d.items()}\n",
    "\n",
    "results = []\n",
    "for r in table:\n",
    "    results.append(r)\n",
    "results = {k: v for d in results for k, v in d.items()}\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.head()\n",
    "#Each column is a patient key in the dictionary, and the rows are Diagnosis and Probabilities (NEED TO INJECT MYSELF NEW ROW HERE FOR RETRIEVAL RAG WHICH DOCUMENTS WHICH PAGES WICH CHUNKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['appendicitis', 'cholecystitis', 'diverticulitis', 'pancreatitis'])\n",
      "- appendicitis\n",
      "  - 20890008\n",
      "    - scores\n",
      "      - Late Physical Examination\n",
      "      - Physical Examination\n",
      "      - Laboratory Tests\n",
      "      - Imaging\n",
      "      - Diagnosis\n",
      "      - Gracious Diagnosis\n",
      "      - Action Parsing\n",
      "      - Treatment Parsing\n",
      "      - Diagnosis Parsing\n",
      "      - Invalid Tools\n",
      "      - Rounds\n",
      "    - answers\n",
      "      - Diagnosis\n",
      "      - Diagnostic Confidence\n",
      "      - Treatment\n",
      "      - Unnecessary Laboratory Tests\n",
      "      - Correct Laboratory Tests\n",
      "        - Inflammation\n",
      "      - Unnecessary Imaging\n",
      "      - Correct Imaging\n",
      "      - Treatment Requested\n",
      "        - Appendectomy\n",
      "        - Antibiotics\n",
      "        - Support\n",
      "      - Treatment Required\n",
      "        - Appendectomy\n",
      "        - Antibiotics\n",
      "        - Support\n",
      "    - retrieved_chunks\n",
      "      - [List Item 0]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "      - [List Item 1]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "      - [List Item 2]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "      - [List Item 3]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "- cholecystitis\n",
      "  - 29897948\n",
      "    - scores\n",
      "      - Late Physical Examination\n",
      "      - Physical Examination\n",
      "      - Laboratory Tests\n",
      "      - Imaging\n",
      "      - Diagnosis\n",
      "      - Gracious Diagnosis\n",
      "      - Action Parsing\n",
      "      - Treatment Parsing\n",
      "      - Diagnosis Parsing\n",
      "      - Invalid Tools\n",
      "      - Rounds\n",
      "    - answers\n",
      "      - Diagnosis\n",
      "      - Diagnostic Confidence\n",
      "      - Treatment\n",
      "      - Unnecessary Laboratory Tests\n",
      "      - Correct Laboratory Tests\n",
      "        - Inflammation\n",
      "        - Liver\n",
      "        - Gallbladder\n",
      "      - Unnecessary Imaging\n",
      "      - Correct Imaging\n",
      "      - Treatment Requested\n",
      "        - Cholecystectomy\n",
      "        - Antibiotics\n",
      "        - Support\n",
      "      - Treatment Required\n",
      "        - Cholecystectomy\n",
      "        - Antibiotics\n",
      "        - Support\n",
      "    - retrieved_chunks\n",
      "      - [List Item 0]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "      - [List Item 1]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "      - [List Item 2]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "      - [List Item 3]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "- diverticulitis\n",
      "  - 24911566\n",
      "    - scores\n",
      "      - Late Physical Examination\n",
      "      - Physical Examination\n",
      "      - Laboratory Tests\n",
      "      - Imaging\n",
      "      - Diagnosis\n",
      "      - Gracious Diagnosis\n",
      "      - Action Parsing\n",
      "      - Treatment Parsing\n",
      "      - Diagnosis Parsing\n",
      "      - Invalid Tools\n",
      "      - Rounds\n",
      "    - answers\n",
      "      - Diagnosis\n",
      "      - Diagnostic Confidence\n",
      "      - Treatment\n",
      "      - Unnecessary Laboratory Tests\n",
      "      - Correct Laboratory Tests\n",
      "        - Inflammation\n",
      "      - Unnecessary Imaging\n",
      "      - Correct Imaging\n",
      "      - Treatment Requested\n",
      "        - Colonoscopy\n",
      "        - Antibiotics\n",
      "        - Support\n",
      "        - Drainage\n",
      "        - Colectomy\n",
      "      - Treatment Required\n",
      "        - Colonoscopy\n",
      "        - Antibiotics\n",
      "        - Support\n",
      "        - Drainage\n",
      "        - Colectomy\n",
      "    - retrieved_chunks\n",
      "      - [List Item 0]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "      - [List Item 1]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "      - [List Item 2]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "      - [List Item 3]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "- pancreatitis\n",
      "  - 29103261\n",
      "    - scores\n",
      "      - Late Physical Examination\n",
      "      - Physical Examination\n",
      "      - Laboratory Tests\n",
      "      - Imaging\n",
      "      - Diagnosis\n",
      "      - Gracious Diagnosis\n",
      "      - Action Parsing\n",
      "      - Treatment Parsing\n",
      "      - Diagnosis Parsing\n",
      "      - Invalid Tools\n",
      "      - Rounds\n",
      "    - answers\n",
      "      - Diagnosis\n",
      "      - Diagnostic Confidence\n",
      "      - Treatment\n",
      "      - Unnecessary Laboratory Tests\n",
      "      - Correct Laboratory Tests\n",
      "        - Inflammation\n",
      "        - Pancreas\n",
      "        - Seriousness\n",
      "      - Unnecessary Imaging\n",
      "      - Correct Imaging\n",
      "      - Treatment Requested\n",
      "        - Support\n",
      "        - Drainage\n",
      "        - ERCP\n",
      "        - Cholecystectomy\n",
      "      - Treatment Required\n",
      "        - Support\n",
      "        - Drainage\n",
      "        - ERCP\n",
      "        - Cholecystectomy\n",
      "    - retrieved_chunks\n",
      "      - [List Item 0]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "      - [List Item 1]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "      - [List Item 2]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "      - [List Item 3]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n"
     ]
    }
   ],
   "source": [
    "# After Analysis\n",
    "# One model\n",
    "    # \"D:\\Users\\orosh\\Documents\\Research\\Datasets\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\analysis\\FULL_INFO_PLI_N_ONLYABNORMAL_BIN_BINABNORMAL_VANILLA_PROBS\\Llama-3.2-1B-Instruct-exl2-4.0bpw_stella_en_400M_v5_evals.pkl\"\n",
    "    # \"D:\\Users\\orosh\\Documents\\Research\\Datasets\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\analysis\\FULL_INFO_PLI_N_ONLYABNORMAL_BIN_BINABNORMAL_VANILLA_PROBS\\Llama-3.2-1B-Instruct-exl2-4.0bpw_stella_en_400M_v5_results.pkl\"\n",
    "    # \"D:\\Users\\orosh\\Documents\\Research\\Datasets\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\analysis\\FULL_INFO_PLI_N_ONLYABNORMAL_BIN_BINABNORMAL_VANILLA_PROBS\\Llama-3.2-1B-Instruct-exl2-4.0bpw_stella_en_400M_v5_scores.pkl\"\n",
    "\n",
    "#Same as above, but for each of these three tables\n",
    "\n",
    "PATH = r\"D:\\Users\\orosh\\Documents\\Research\\Datasets\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\analysis\\FULL_INFO_PLI_N_ONLYABNORMAL_BIN_BINABNORMAL_VANILLA_PROBS\\Llama-3.2-1B-Instruct-exl2-4.0bpw_stella_en_400M_v5_evals.pkl\"\n",
    "\n",
    "m_results = pickle.load(open(PATH, 'rb'))\n",
    "\n",
    "print(m_results.keys()) #dict_keys(['appendicitis', 'cholecystitis', 'diverticulitis', 'pancreatitis'])\n",
    "\n",
    "#flatten the dictionary on patients (i.e. keep only one patient key and get rid of the rest)\n",
    "def flatten_dict(d):\n",
    "    \"\"\"\n",
    "    Recursively explores the structure of a dictionary.\n",
    "    If a level has keys that are integers (patient IDs), it keeps only the first one.\n",
    "    \"\"\"\n",
    "    # First, identify integer keys (patient IDs)\n",
    "    int_keys = [k for k in d.keys() if isinstance(k, int) or isinstance(k, np.int64)]\n",
    "    if int_keys:\n",
    "        # Keep only the first integer key\n",
    "        first_key = int_keys[0]\n",
    "        # Delete other integer keys\n",
    "        for k in int_keys:\n",
    "            if k != first_key:\n",
    "                del d[k]\n",
    "\n",
    "    # Now, safely iterate over the remaining keys\n",
    "    for key in list(d.keys()):\n",
    "        value = d[key]\n",
    "        if isinstance(value, dict):\n",
    "            flatten_dict(value)\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    flatten_dict(item)\n",
    "\n",
    "\n",
    "flatten_dict(m_results)\n",
    "\n",
    "def print_dict_structure(d, indent=0):\n",
    "    \"\"\"Recursively prints the structure of a dictionary.\"\"\"\n",
    "    \"\"\"If the key is an int, it is a patient ID, in that case keep only one and get rid of the rest\"\"\"\n",
    "    for key in d:\n",
    "        print('  ' * indent + f'- {key}')\n",
    "        if isinstance(d[key], dict):\n",
    "            print_dict_structure(d[key], indent + 1)\n",
    "        elif isinstance(d[key], list):\n",
    "            for index, item in enumerate(d[key]):\n",
    "                if isinstance(item, dict):\n",
    "                    print('  ' * (indent + 1) + f'- [List Item {index}]')\n",
    "                    print_dict_structure(item, indent + 2)\n",
    "\n",
    "# Print the structure\n",
    "print_dict_structure(m_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAJECTORY_DIFFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definitions\n",
    "DIAGNOSIS = \"cholecystitis\"\n",
    "MIN_TRAJ_LEN = 1\n",
    "DIFF_TRAJ_LEN = 2\n",
    "# PATH_WITHOUT_RAG = r\"D:\\Users\\orosh\\Documents\\Research\\Datasets\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\cholecystitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_25-11-2024_14-19-56_BIN\\cholecystitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_25-11-2024_14-19-56_BIN_results.pkl\"\n",
    "# PATH_WITH_RAG = r\"D:\\Users\\orosh\\DOCUME~1\\Research\\Datasets\\MIMIC-~1.1-F\\logs\\CH0E97~1.0BP\\CHOLEC~1.PKL\"\n",
    "PATH_WITHOUT_RAG = r\"\\\\?\\UNC\\chansey.umcn.nl\\pelvis\\projects\\romainandre\\Datasets\\MIMIC\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\cholecystitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_04-12-2024_04-13-40\\cholecystitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_04-12-2024_04-13-40_results.pkl\"\n",
    "PATH_WITH_RAG = r\"\\\\?\\UNC\\chansey.umcn.nl\\pelvis\\projects\\romainandre\\Datasets\\MIMIC\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\cholecystitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_stella_en_400M_v5_05-12-2024_09-00-47\\cholecystitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_stella_en_400M_v5_05-12-2024_09-00-47_results.pkl\"\n",
    "OUTPUT_BASE = r\"D:\\Users\\orosh\\Documents\\Research\\Datasets\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\analysis\\output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the tables\n",
    "m_results = read_from_pickle_file(PATH_WITHOUT_RAG)\n",
    "m_results = {k: v for d in m_results for k, v in d.items()}\n",
    "\n",
    "m_results_rag = read_from_pickle_file(PATH_WITH_RAG)\n",
    "m_results_rag = {k: v for d in m_results_rag for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 29897948\n",
      "  - input\n",
      "  - documents\n",
      "  - output\n",
      "  - intermediate_steps\n",
      "  - step_data\n",
      "    - [List Item 0]\n",
      "      - step\n",
      "      - inputs_for_prompt\n",
      "        - input\n",
      "        - documents\n",
      "        - agent_scratchpad\n",
      "      - prompt_text\n",
      "      - retrieved_docs_content\n",
      "      - full_output\n",
      "    - [List Item 1]\n",
      "      - step\n",
      "      - inputs_for_prompt\n",
      "        - input\n",
      "        - documents\n",
      "        - agent_scratchpad\n",
      "      - prompt_text\n",
      "      - retrieved_docs_content\n",
      "      - full_output\n",
      "    - [List Item 2]\n",
      "      - step\n",
      "      - inputs_for_prompt\n",
      "        - input\n",
      "        - documents\n",
      "        - agent_scratchpad\n",
      "      - prompt_text\n",
      "      - retrieved_docs_content\n",
      "      - full_output\n",
      "    - [List Item 3]\n",
      "      - step\n",
      "      - inputs_for_prompt\n",
      "        - input\n",
      "        - documents\n",
      "        - agent_scratchpad\n",
      "      - prompt_text\n",
      "      - retrieved_docs_content\n",
      "      - full_output\n",
      "  - retrieval\n",
      "    - 0\n",
      "      - [List Item 0]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "      - [List Item 1]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "      - [List Item 2]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n",
      "      - [List Item 3]\n",
      "        - chunk_id\n",
      "        - document_reference\n",
      "        - page_number\n",
      "        - token_size\n",
      "        - order_in_document\n",
      "        - content\n"
     ]
    }
   ],
   "source": [
    "#Print current structure of RAG pickle\n",
    "\n",
    "#copy m_results_rag\n",
    "m_results_rag_copy = m_results_rag.copy()\n",
    "\n",
    "flatten_dict(m_results_rag_copy)\n",
    "print_dict_structure(m_results_rag_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Print each elements of step_data[1]\n",
    "\n",
    "# print(m_results_rag[26076363][\"step_data\"][1])\n",
    "\n",
    "# #save it as json\n",
    "# import json\n",
    "# data = m_results_rag[26076363][\"step_data\"][1]\n",
    "\n",
    "\n",
    "# with open(join(OUTPUT_BASE, \"step_data.json\"), \"w\") as f:\n",
    "#     json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients meeting criteras: [26013833, 24516999]\n",
      "Patient selected: 26013833\n"
     ]
    }
   ],
   "source": [
    "#Search for patient that fills the criterias\n",
    "#Criteria 1: DIAGNOSIS not found in output of model without RAG but found in output of model with RAG\n",
    "#Criteria 2: The patient has at least MIN_TRAJ_LEN intermediate steps in both outputs\n",
    "patient_keys = []\n",
    "for patient in m_results:\n",
    "    #Look only for the substring between \"Final Diagnosis:\" and \"Treatment:\"\n",
    "    #If the output does not contain Final Diagnosis or Treatment, skip the patient\n",
    "    if \"Final Diagnosis:\" not in m_results[patient]['output'] or \"Treatment:\" not in m_results[patient]['output']:\n",
    "        continue\n",
    "    if \"Final Diagnosis:\" not in m_results_rag[patient]['output'] or \"Treatment:\" not in m_results_rag[patient]['output']:\n",
    "        continue\n",
    "    sub = m_results[patient]['output'].split(\"Final Diagnosis:\")[1].split(\"Treatment:\")[0]\n",
    "    sub = sub.strip().replace(\"\\n\", \" \").lower()\n",
    "    sub_rag = m_results_rag[patient]['output'].split(\"Final Diagnosis:\")[1].split(\"Treatment:\")[0]\n",
    "    sub_rag = sub_rag.strip().replace(\"\\n\", \" \").lower()\n",
    "    # if DIAGNOSIS in m_results_rag[patient]['output'] and DIAGNOSIS not in m_results[patient]['output']:\n",
    "    if DIAGNOSIS not in sub and DIAGNOSIS in sub_rag:\n",
    "        if len(m_results_rag[patient]['intermediate_steps']) >= MIN_TRAJ_LEN and len(m_results[patient]['intermediate_steps']) >= MIN_TRAJ_LEN:\n",
    "            if len(m_results_rag[patient]['intermediate_steps']) >= len(m_results[patient]['intermediate_steps']) + DIFF_TRAJ_LEN:\n",
    "                patient_keys.append(patient)\n",
    "patient_key = patient_keys[0] if patient_keys else None\n",
    "print(\"Patients meeting criteras:\", patient_keys)\n",
    "print(\"Patient selected:\", patient_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print pathway of the patient for each patient; i.e. save full traject of the patient step per step in a txt file per patient per model\n",
    "\n",
    "#Example of what is in a patient\n",
    "# INPUT: \n",
    "#  ___ w/breast CA, polycytemia ___ presents with vomiting.  Pt had had 1 month of nausea, nonradiating epigastric abd pain,  anorexia and 10 lb weight loss. Was seen in ___ GI clinic for  evaluation of this and found to have elevated LFTs, elevated T.  bili; RUQ u/s confirmed biliary dilatation with ?mass v. biliary  sludge. Pt scheduled for an outpatient ERCP w/ Dr. ___  ___. However, yesterday AM patient had worsening nausea,  intractable emesis and loose stools so presented to the ED. In ED ERCP contacted. Pt given 1.5Lns and zofran.  ROS: +as above, otherwise reviewed and negative    Past Medical History: Mitral valve prolapse  Hypertension, essential  Osteopenia  Breast CANCER, left ___  SPINAL STENOSIS - LUMBAR L4-5  Degeneration of lumbar or lumbosacral intervertebral disc  SPONDYLOLISTHESIS - L4-5 grade 1  Stroke, small vessel  Hyperlipemia with goal LDL<100  Polycythemia ___  ___ of shoulder  HOH (hard of hearing)  Chronic renal insufficiency, stage III (moderate)  Gait instability     Social History: ___ Family History: sister CVA \n",
    "\n",
    "# OUTPUT: \n",
    "#  The patient's imaging studies are not available, but I can consider the possibility of a gastrointestinal complication based on the patient's symptoms and medical history.\n",
    "\n",
    "# Final Diagnosis: Gastrointestinal Complication\n",
    "# Treatment: None\n",
    "\n",
    "# Format. \n",
    "\n",
    "# INTERMEDIATE STEPS: \n",
    "#  [(AgentAction(tool='Physical Examination', tool_input={'action_input': None}, log=\"After reviewing the patient's history, I have considered the following factors: breast cancer, polycythemia, hypertension, essential osteopenia, spinal stenosis, lumbar disc degeneration, stroke, hyperlipidemia, polycythemia, hard of hearing, chronic renal insufficiency, and gait instability. I have also taken into account the patient's recent symptoms of worsening nausea, intractable emesis, and loose stools, which suggests a possible gastrointestinal complication.\\n\\nAction: Physical Examination\\nAction Input: None\", custom_parsings=0), 'Physical Examination:\\n Vitals: T:98.1 BP:134/69 P:85 R:16 O2:96%ra   PAIN: 0 General: nad EYES: anicteric Lungs: clear CV: rrr no m/r/g Abdomen: bowel sounds present, soft, nt/nd Ext: no e/c/c Skin: no rash Neuro: alert, follows commands    \\n'), (AgentAction(tool='Laboratory Tests', tool_input={'action_input': ['None']}, log=\"The patient's physical examination reveals signs of dehydration, tachycardia, and abdominal tenderness, which are consistent with a possible gastrointestinal complication.\\n\\nAction: Laboratory Tests\\nAction Input: None\", custom_parsings=0), 'Laboratory Tests:\\nNone: N/A\\n'), (AgentAction(tool='Provide a diagnosis and treatment OR a valid tool. That', tool_input={'action_input': None}, log=\"The laboratory tests do not provide any additional information that would be relevant to the patient's current condition.\\n\\nAction: Imaging\\nAction Input: None\", custom_parsings=0), 'Provide a diagnosis and treatment OR a valid tool. That is not a valid tool, try one of [Physical Examination, Laboratory Tests, Imaging].')] \n",
    "\n",
    "# RETRIEVAL: \n",
    "#  {1: [{'chunk_id': 'chunk_361', 'document_reference': '/container/guidelines/pdf/cdm_cholecystitis_s13017-020-00336-x.pdf', 'page_number': 20, 'token_size': 252, 'order_in_document': 2, 'content': '00336 - x. additional file 1. appendix 1 and 2 abbreviations acc : acute calculous cholecystitis ; grade : grading of recommendations assessment, development and evaluation ; tg : tokyo guidelines ; cc : consensus conference ; cbds : common bile duct stone ; rct : randomized controlled trial ; lr : likelihood ratio ; us : ultrasound ; pswe : point shear - wave elastography ; auc : area under the curve ; smi : superb microvascular imaging ; hida : hepatobiliary iminodiacetic acid ; ct : computed tomography ; mri : magnetic resonance imaging ; ercp : endoscopic retrograde colangio - pancreatography ; lfts : liver function tests ; ggt : gamma - glutamyl transpeptidase ; alt : alanine aminotransferase ; ioc : intra - operative cholangiography ; ppv : positive predictive value ; npv : negative predictive value ; alp : alkaline phosphatase ; eus : endoscopic ultrasound ; mcrp : magnetic resonance colangio - pancreatography ; lus : laparoscopic ultrasound ; elc : early lap'}, {'chunk_id': 'chunk_599', 'document_reference': '/container/guidelines/pdf/cdm_pancreatitis_s13017-019-0247-0.pdf', 'page_number': 11, 'token_size': 252, 'order_in_document': 0, 'content': 'laparotomy, intraperitoneal vs. extraperitoneal, early vs. delayed )? 6. when is cholecystectomy recommended and what is the correct timing? statements ( indications for emergent ercp ) 1. routine ercp with acute gallstone pancreatitis is not indicated ( grade 1a ). 2. ercp in patients with acute gallstone pancreatitis and cholangitis is indicated ( grade 1b ). 3. ercp in acute gallstone pancreatitis with common bile duct obstruction is indicated ( grade 2b ). 4. ercp in patients with predicted severe acute gallstone pancreatitis without cholangitis or common bile duct obstruction cannot be recommended at this time ( grade 2b ). discussion a systematic review of seven randomized controlled trials ( rct ) comprising 757 participants found no evidence to support routine ercp for all pa - tients with acute gallstone pancreatitis ( agp ) [ 92 ]. there was no evidence to suggest that the results were dependent on the predicted severity of agp. however, concerns have been raised of study design limitations, lack of pooled sample size with predicted severe agp, and ercp'}, {'chunk_id': 'chunk_609', 'document_reference': '/container/guidelines/pdf/cdm_pancreatitis_s13017-019-0247-0.pdf', 'page_number': 13, 'token_size': 252, 'order_in_document': 1, 'content': 'patient is clinically improving [ 111, 112 ]. routine intraoperative cholangiography seems to be unnecessary in patients with mild gallstone pancreatitis and normalizing biliru - bin levels [ 113 ]. if ercp was performed during the index admission, the risk for recurrent biliary events, es - pecially recurrent agp, was diminished but still higher than same - admission cholecystectomy. a multicenter rct with 266 patients concluded that interval chole - cystectomy resulted in more gallstone - related complica - tions, especially recurrent pancreatitis and colics, without increased cholecystectomy - related complica - tions [ 114 ]. there is a single retrospective study of tim - ing of cholecystectomy in patients with moderate to severe agp with peripancreatic fluid collections [ 115 ]. this study reported more complications after early cholecystectomy. open abdomen questions 1. which are the indications for open abdomen in case of severe acute pancreatitis? 2. what is the best temporary abdominal closure system for open abdomen? 3. what is the correct timing for dressing changes'}, {'chunk_id': 'chunk_620', 'document_reference': '/container/guidelines/pdf/cdm_pancreatitis_s13017-019-0247-0.pdf', 'page_number': 15, 'token_size': 252, 'order_in_document': 2, 'content': 'acute physiology and chronic health evaluation ; bisap : bedside index of severity of acute pancreatitis ; bmi : body mass index ; bun : blood urea nitrogen ; cect : contrast - enhanced computed tomography ; crp : c - reactive protein ; ct : computed tomography ; ctsi : ct severity index ; dbc : determinant - based classification of acute pancreatitis severity ; dcl : decompressive laparotomy ; dpr : direct peritoneal resuscitation ; ercp : endoscopic retrograde cholangiopancreatography ; eus : endoscopic ultrasound ; fna : fine - needle aspiration ; grade : grading of recommendations assessment, development and evaluation ; hct : hematocrit ; iah : intra - abdominal hypertension ; iap : intra - abdominal pressure ; icu : intensive care unit ; ldh : lactate dehydrogenase ; mic : minimal inhibitory concentration ; mrcp : magnetic resonance cholangiopancreatography ; mri : magnetic resonance imaging ; npwt : negative pressure wound therapy ; ns : normal saline ; nsaid : non - steroidal anti - inflammatory drug ; oa : open abdomen ;'}]} \n",
    "\n",
    "def patient_to_string(patient):\n",
    "    #Input, then each intermediate steps, then output, all in a human readable well spaced and titled format\n",
    "    #Retrieval is optional, so check if it exists, if it exist it should be in between each intermediate step and the output (after first input and after each intermediate step)\n",
    "\n",
    "    is_rag = 'retrieval' in patient\n",
    "    step_count = 0\n",
    "\n",
    "    patient_str = \"\"\n",
    "    patient_str += \"# --- INPUT ---\\n\"\n",
    "    patient_str += patient['input'] + \"\\n\\n\"\n",
    "    step_count += 1\n",
    "\n",
    "    if is_rag:\n",
    "        patient_str += f\"# --- RETRIEVAL {step_count} ---\\n\"\n",
    "        for chunk in patient['retrieval'][step_count-1]:\n",
    "            patient_str += f\"Document: {chunk['document_reference']}\\n\"\n",
    "            patient_str += f\"Page: {chunk['page_number']}\\n\"\n",
    "            patient_str += f\"Content: {chunk['content']}\\n\\n\"\n",
    "\n",
    "    patient_str += \"# --- INTERMEDIATE STEPS ---\\n\"\n",
    "    for i, (action, log) in enumerate(patient['intermediate_steps']):\n",
    "        patient_str += f\"# --- STEP {i + 1} ---\\n\"\n",
    "        patient_str += f\"{action}:\\n {log}\\n\\n\"\n",
    "\n",
    "        step_count += 1\n",
    "\n",
    "        if is_rag:\n",
    "            patient_str += f\"# --- RETRIEVAL {step_count} ---\\n\"\n",
    "            for chunk in patient['retrieval'][step_count-1]:\n",
    "                patient_str += f\"Document: {chunk['document_reference']}\\n\"\n",
    "                patient_str += f\"Page: {chunk['page_number']}\\n\"\n",
    "                patient_str += f\"Content: {chunk['content']}\\n\\n\"\n",
    "\n",
    "    patient_str += \"# --- OUTPUT ---\\n\"\n",
    "    patient_str += patient['output'] + \"\\n\\n\"\n",
    "\n",
    "    return patient_str\n",
    "\n",
    "#Save it to ./patient_trajectories/DIAGNOSIS/Patient_key(_rag).txt\n",
    "#Make sure to create the directories if they do not exist\n",
    "import os\n",
    "output_dir = join(OUTPUT_BASE, \"patient_trajectories\", DIAGNOSIS)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for patient_key in patient_keys:\n",
    "    output_path = join(output_dir, f\"{patient_key}.txt\")\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(patient_to_string(m_results[patient_key]))\n",
    "    output_path_rag = join(output_dir, f\"{patient_key}_rag.txt\")\n",
    "    with open(output_path_rag, 'w') as f:\n",
    "        f.write(patient_to_string(m_results_rag[patient_key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functionize\n",
    "def SaveTraj(Diagnosis, Doc_without_rag, Doc_with_rag, Min_Traj_Len, Diff_traj_len):\n",
    "    #Load the tables\n",
    "    m_results = read_from_pickle_file(Doc_without_rag)\n",
    "    m_results = {k: v for d in m_results for k, v in d.items()}\n",
    "\n",
    "    m_results_rag = read_from_pickle_file(Doc_with_rag)\n",
    "    m_results_rag = {k: v for d in m_results_rag for k, v in d.items()}\n",
    "\n",
    "    #Search for patient that fills the criterias\n",
    "    #Criteria 1: DIAGNOSIS not found in output of model without RAG but found in output of model with RAG\n",
    "    #Criteria 2: The patient has at least MIN_TRAJ_LEN intermediate steps in both outputs\n",
    "    patient_keys = []\n",
    "    for patient in m_results:\n",
    "        #Look only for the substring between \"Final Diagnosis:\" and \"Treatment:\"\n",
    "        #If the output does not contain Final Diagnosis or Treatment, skip the patient\n",
    "        if \"Final Diagnosis:\" not in m_results[patient]['output'] or \"Treatment:\" not in m_results[patient]['output']:\n",
    "            continue\n",
    "        if \"Final Diagnosis:\" not in m_results_rag[patient]['output'] or \"Treatment:\" not in m_results_rag[patient]['output']:\n",
    "            continue\n",
    "        sub = m_results[patient]['output'].split(\"Final Diagnosis:\")[1].split(\"Treatment:\")[0]\n",
    "        sub = sub.strip().replace(\"\\n\", \" \").lower()\n",
    "        sub_rag = m_results_rag[patient]['output'].split(\"Final Diagnosis:\")[1].split(\"Treatment:\")[0]\n",
    "        sub_rag = sub_rag.strip().replace(\"\\n\", \" \").lower()\n",
    "        # if DIAGNOSIS in m_results_rag[patient]['output'] and DIAGNOSIS not in m_results[patient]['output']:\n",
    "        if Diagnosis not in sub and Diagnosis in sub_rag:\n",
    "            if len(m_results_rag[patient]['intermediate_steps']) >= Min_Traj_Len and len(m_results[patient]['intermediate_steps']) >= Min_Traj_Len:\n",
    "                if len(m_results_rag[patient]['intermediate_steps']) >= len(m_results[patient]['intermediate_steps']) + Diff_traj_len:\n",
    "                    patient_keys.append(patient)\n",
    "    patient_key = patient_keys[0] if patient_keys else None\n",
    "    print(\"Patients meeting criteras:\", patient_keys)\n",
    "    print(\"Patient selected:\", patient_key)\n",
    "\n",
    "    #Iterate over the patient keys and save the patient trajectory\n",
    "    output_dir = join(OUTPUT_BASE, \"patient_trajectories\", Diagnosis)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for patient_key in patient_keys:\n",
    "        output_path = join(output_dir, f\"{patient_key}.txt\")\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(patient_to_string(m_results[patient_key]))\n",
    "        output_path_rag = join(output_dir, f\"{patient_key}_rag.txt\")\n",
    "        with open(output_path_rag, 'w') as f:\n",
    "            f.write(patient_to_string(m_results_rag[patient_key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients meeting criteras: [29874547, 22208156]\n",
      "Patient selected: 29874547\n",
      "Patients meeting criteras: [27767349]\n",
      "Patient selected: 27767349\n",
      "Patients meeting criteras: [26013833, 24516999]\n",
      "Patient selected: 26013833\n",
      "Patients meeting criteras: [24672980, 25049191, 29581468, 24236230, 26832968, 22487020, 29221033, 28766133, 29203477, 29917241, 28612790, 25874857, 24917571]\n",
      "Patient selected: 24672980\n"
     ]
    }
   ],
   "source": [
    "Files_Path = {\n",
    "    \"appendicitis\": [\n",
    "        r\"\\\\?\\UNC\\chansey.umcn.nl\\pelvis\\projects\\romainandre\\Datasets\\MIMIC\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\appendicitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_03-12-2024_16-44-43\\appendicitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_03-12-2024_16-44-43_results.pkl\",\n",
    "        r\"\\\\?\\UNC\\chansey.umcn.nl\\pelvis\\projects\\romainandre\\Datasets\\MIMIC\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\appendicitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_stella_en_400M_v5_04-12-2024_17-35-25\\appendicitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_stella_en_400M_v5_04-12-2024_17-35-25_results.pkl\",\n",
    "    ],\n",
    "    \"diverticulitis\": [\n",
    "        r\"\\\\?\\UNC\\chansey.umcn.nl\\pelvis\\projects\\romainandre\\Datasets\\MIMIC\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\diverticulitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_04-12-2024_01-28-06\\diverticulitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_04-12-2024_01-28-06_results.pkl\",\n",
    "        r\"\\\\?\\UNC\\chansey.umcn.nl\\pelvis\\projects\\romainandre\\Datasets\\MIMIC\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\diverticulitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_stella_en_400M_v5_05-12-2024_04-32-49\\diverticulitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_stella_en_400M_v5_05-12-2024_04-32-49_results.pkl\",\n",
    "    ],\n",
    "    \"cholecystitis\": [\n",
    "        r\"\\\\?\\UNC\\chansey.umcn.nl\\pelvis\\projects\\romainandre\\Datasets\\MIMIC\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\cholecystitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_04-12-2024_04-13-40\\cholecystitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_04-12-2024_04-13-40_results.pkl\",\n",
    "        r\"\\\\?\\UNC\\chansey.umcn.nl\\pelvis\\projects\\romainandre\\Datasets\\MIMIC\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\cholecystitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_stella_en_400M_v5_05-12-2024_09-00-47\\cholecystitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_stella_en_400M_v5_05-12-2024_09-00-47_results.pkl\",\n",
    "    ],\n",
    "    \"pancreatitis\": [\n",
    "        r\"\\\\?\\UNC\\chansey.umcn.nl\\pelvis\\projects\\romainandre\\Datasets\\MIMIC\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\pancreatitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_04-12-2024_11-38-00\\pancreatitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_04-12-2024_11-38-00_results.pkl\",\n",
    "        r\"\\\\?\\UNC\\chansey.umcn.nl\\pelvis\\projects\\romainandre\\Datasets\\MIMIC\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\pancreatitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_stella_en_400M_v5_05-12-2024_17-27-57\\pancreatitis_ZeroShot_Llama-3.1-70B-Instruct-exl2-4.0bpw_stella_en_400M_v5_05-12-2024_17-27-57_results.pkl\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "MIN_TRAJ_LEN = 1\n",
    "DIFF_TRAJ_LEN = 2\n",
    "OUTPUT_BASE = r\"D:\\Users\\orosh\\Documents\\Research\\Datasets\\mimic-iv-ext-cdm-1.1-from-iv\\logs\\analysis\\output\"\n",
    "\n",
    "for diagnosis, paths in Files_Path.items():\n",
    "    SaveTraj(diagnosis, paths[0], paths[1], MIN_TRAJ_LEN, DIFF_TRAJ_LEN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimic-cdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
